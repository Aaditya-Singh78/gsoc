---
title: Week 4
author: Abdelrahman Jamal
---
<!--
SPDX-License-Identifier: CC-BY-SA-4.0

SPDX-FileCopyrightText: 2023 Abdelrahman Jamal <abdelrahmanjamal5565@gmail.com>
-->

*(June,21,2023)*

## Attendees:

* [Abdelrahman](https://github.com/Hero2323)
* [Anupam](https://github.com/ag4ums)
* [Gaurav](https://github.com/GMishx)
* [Shaheem](https://github.com/shaheemazmalmmd)

## Updates:

### Copyright Dataset Creation
  - Initiated the process of curating a copyright dataset. Instead of manual procedures via the Fossology UI, automation was explored through the chat-gpt-3.5 API. A series of functions were designed to traverse directories, extract commented content in files, and forward that text along with a specific prompt to the chat-gpt API. This was meant to isolate any copyright content within. Though mostly successful, iterations were required for improvement. The related code is accessible [here](https://gist.github.com/Hero2323/bff12400cec5ab54467ea35ba89e976f), and my findings are hosted [here](https://drive.google.com/drive/folders/10cvdBEWOgr2JSWqR7X7Oz0xl-Nn2VcGU?usp=drive_link).

### Methodology Challenge
  - The aforementioned approach, albeit innovative, was rendered non-viable for the project due to the necessity of employing Fossology for the dataset creation, ensuring the rectification of its false positives.

### Fossology API
  - Acquired information about the existence of a Fossology API capable of extracting Fossology-generated copyright statements. This can be harnessed for dataset formulation.

### LDA Model
  - Executed a basic LDA (Latent Dirichlet Allocation) model centered around two topics - copyright and non-copyright. The results were promising, indicating pertinent associations. The respective code can be located [here](https://gist.github.com/Hero2323/3e22bc0af40323d502de6f26ef2886ab).

## Problems and Solutions:

### Problem 1
- The task of manually creating a dataset is monotonous, protracted, and susceptible to errors.

### Solution 1
- Automated the task employing chatGPT. However, it necessitated meticulous prompt structuring to derive semi-reliable results.

### Problem 2
- Uncertainty about file segments to forward to chatGPT for copyright extraction.

### Solution 2
- Developed a function to solely capture commented lines from predominant extensions. In instances of its inadequacy, the entire file was dispatched to chatGPT, a measure which eventually proved counterproductive. Subsequent insights from Gaurav introduced me to [Nirjas, a Python library under the Fossology project](https://github.com/fossology/Nirjas), already adept at this task.

## Conclusion and Further Plans:

### Dataset Creation 
- Engage in the formulation of the dataset leveraging the Fossology API.


